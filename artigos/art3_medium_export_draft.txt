---

Redes Neurais do Zero (em Rust): Parte 3‚Ää-‚ÄäRetropropaga√ß√£o
Este artigo √© a 3¬™ parte de uma s√©rie relatando a constru√ß√£o de uma rede neural na linguagem Rust. Parte 1. Parte 2.
O autor do v√≠deo n√£o estava brincando quando disse que leva um tempo para compreender completamente o algoritmo de retropropaga√ß√£o. Pessoalmente, a explica√ß√£o provida no material fonte n√£o foi suficiente para que eu pudesse visualizar a estrutura do c√≥digo desse fragmento. Em especial, senti muita dificuldade em aplicar a transi√ß√£o de um √∫nico neur√¥nio, a vers√£o simplificada, para o caso de m√∫ltiplos neur√¥nios com opera√ß√µes matriciais.
Este artigo √© uma tentativa de descrever todo o processo de aprendizagem pelo qual passei nessa trajet√≥ria, incluindo os erros e as frustra√ß√µes encontradas ao tentar traduzir a matem√°tica em c√≥digo fonte.
Mensurando o Desempenho da¬†Rede
Uma necessidade fundamental das redes neurais √© mensurar o qu√£o pr√≥xima da resposta correta o algoritmo est√°. Esse processo √© modelado por uma fun√ß√£o de custo: quanto menor o custo, mais pr√≥ximo da resposta correta est√° o resultado.¬†
A fun√ß√£o de custo tamb√©m pode ser compreendida como uma m√©trica do erro da rede neural. Portanto, o desempenho da rede neural √© otimizado reduzindo o valor de erro. Na matem√°tica, esse processo √© conhecido por minimiza√ß√£o.
Utilizando um gr√°fico como auxiliar descritivo, a minimiza√ß√£o de uma fun√ß√£o y = f(x) pode ser feita escolhendo uma posi√ß√£o inicial (valor de x) e escolhendo uma dire√ß√£o de ajuste (esquerda ou direita) que leva a um valor reduzido o valor de y. Esse processo pode ser repetido iterativamente, ajustando o tamanho dos passos na dire√ß√£o desejada at√© alcan√ßar um m√≠nimo local.
Ilustra√ß√£o de uma fun√ß√£o unidimensional. Os ajustes s√£o equivalentes a mover o ponto para a esquerda, reduzindo o valor de x, ou para a direita, aumentando o valor de¬†x.A escolha aqui envolve apenas 2 dire√ß√µes pois o dom√≠nio de uma fun√ß√£o com uma √∫nica vari√°vel √© um espa√ßo unidimensional: s√≥ podemos aumentar ou reduzir o valor de x para obter um novo y. Para uma fun√ß√£o com m√∫ltiplas vari√°veis, como √© o caso da rede neural com seus pesos e vieses, o espa√ßo da fun√ß√£o √© multidimensional.¬†
Nesse espa√ßo a dire√ß√£o dos passos de minimiza√ß√£o √© descrita por um vetor, cujos componentes descrevem a varia√ß√£o de cada uma das vari√°veis de entrada da fun√ß√£o. Esse vetor √© denominado gradiente e nos diz em que dire√ß√£o devemos ajustar cada vari√°vel, cada peso e cada vi√©s, para que o resultado da rede neural se aproxime do resultado desejado.
Fun√ß√£o multidimensional. A dire√ß√£o de ajuste de cada passo √© definida por um vetor com as dimens√µes do espa√ßo da¬†fun√ß√£o.Obs: Matematicamente o gradiente √© um vetor que aponta a dire√ß√£o dos m√°ximos da fun√ß√£o.  Isso significa que, em uma rede neural, o ajuste deve ser feito na dire√ß√£o contr√°ria atrav√©s da subtra√ß√£o do gradiente.
Como o n√∫mero de pesos e vieses em uma rede neural estende-se al√©m dos milhares, calcular todas as posi√ß√µes desse vetor de uma √∫nica vez √© uma tarefa que parece invi√°vel. O algoritmo de retropropaga√ß√£o oferece uma alternativa para que esse c√°lculo seja realizado iterativamente: partindo da camada de sa√≠da da nossa rede neural, o gradiente de cada camada pode ser calculado com base nos valores de sua vizinhan√ßa imediata.
Retropropaga√ß√£o: Camada de¬†Sa√≠da
Embora eu n√£o tenha compreendido completamente a explica√ß√£o do v√≠deo original, uma coisa ficou clara: o c√°lculo da retropropaga√ß√£o da camada de sa√≠da da rede neural √© distinto das camadas ocultas.¬†
Esse detalhe √© bem intuitivo quando consideramos a sequ√™ncia de camadas: o resultado da camada final √© diretamente compar√°vel com o resultado esperado. Portanto, o erro dessa camada pode ser calculado com base nesse resultado.¬†
J√° as camadas ocultas n√£o tem essa equival√™ncia. A ativa√ß√£o da pen√∫ltima camada impacta apenas na ativa√ß√£o da camada seguinte, portanto, o erro dessa camada depende do erro da camada final. Isso se repete sucessivamente para todas as camadas anteriores: o erro da sa√≠da √© propagado camada por camada na dire√ß√£o reversa.¬†

---

Bom, vamos revisar as defini√ß√µes. O objetivo da retropropaga√ß√£o √© minimizar o resultado da fun√ß√£o de custo. Para isso devemos encontrar a inclina√ß√£o da fun√ß√£o no ponto do resultado. Relembrando os conceitos iniciais de c√°lculo, a inclina√ß√£o de uma fun√ß√£o √© a taxa de varia√ß√£o do resultado em fun√ß√£o do valor de entrada.¬†
Esse conceito √© representado pelas derivadas: a derivada f'(x) indica a dire√ß√£o e magnitude da inclina√ß√£o da fun√ß√£o em torno do ponto x.
A inclina√ß√£o da fun√ß√£o pode ser vista como a dire√ß√£o da linha no gr√°fico: para baixo ou para cima. O valor da derivada indica o qu√£o √≠ngreme s√£o as redondezas da fun√ß√£o naquele¬†ponto.Para fun√ß√µes multivariadas, a taxa de varia√ß√£o em rela√ß√£o a cada vari√°vel √© dada por derivadas parciais. Com essa mem√≥ria ativada, podemos entrar no c√°lculo do gradiente da camada final.
O gradiente da camada final √© calculado com base em 3 fatores:
Valor de ativa√ß√£o da camada anterior
Pesos da camada de sa√≠da
Vieses da camada de sa√≠da

Novamente isso √© bem intuitivo: o valor de ativa√ß√£o dessa camada √© gerado pela combina√ß√£o desses 3 fatores. Portanto, se eu preciso modificar o valor de sa√≠da para minimizar o valor de custo, ao menos 1 desses fatores deve ser ajustado.

---

A fun√ß√£o de custo adotada nos v√≠deos √© o erro quadr√°tico m√©dio. Nessa fun√ß√£o, o custo C‚Çô do resultado final √© dado pelo quadrado da diferen√ßa entre a ativa√ß√£o da camada de sa√≠da (a‚Çô) e o resultado esperado (y):
Obs: nas equa√ß√µes utilizadas, o subscrito n indica que a equa√ß√£o refere-se a n-√©sima camada da rede neural.
Para reduzir a diferen√ßa desses resultados precisamos ajustar os par√¢metros da fun√ß√£o: a‚Çô ou y. Como o resultado esperado √© fixo, a √∫nica op√ß√£o √© ajustar o valor de a‚Çô. Formalmente a taxa de altera√ß√£o no custo por modifica√ß√µes no valor de a‚Çô √© dado pela derivada parcial em rela√ß√£o a vari√°vel: ‚àÇC‚Çô/‚àÇa
Como a‚Çô √© o resultado de todo o processamento da rede neural, n√£o podemos simplesmente modificar esse valor. Precisamos ajustar os componentes de a‚Çô e determinar seu efeito no resultado final:
Equa√ß√µes para a obten√ß√£o da ativa√ß√£o de neur√¥nios da camada n na rede¬†neuralO valor de a‚Çô √© constitu√≠do pela composi√ß√£o de 2 fun√ß√µes: a soma ponderada pelos pesos e vieses (z‚Çô) e a fun√ß√£o de ativa√ß√£o  œÉ. Essa soma ponderada √© nomeada agora para possibilitar uma representa√ß√£o mais compacta da derivada parcial: ‚àÇa‚Çô/‚àÇz‚Çô. Essa derivada representa o quanto uma altera√ß√£o no valor da soma afeta o valor de a‚Çô.
Como z‚Çô √© uma fun√ß√£o, precisamos saber o quanto cada componente dessa soma ponderada afeta o seu valor. Aqui podemos manipular o valor dos pesos w‚Çô e dos vieses b‚Çô. Portanto, a taxa de varia√ß√£o de z‚Çô √© dada por duas derivadas parciais: a varia√ß√£o em rela√ß√£o aos pesos √© dada por ‚àÇz‚Çô\‚àÇw‚Çô e a taxa de varia√ß√£o em rela√ß√£o aos vieses √© dada por ‚àÇz‚Çô\‚àÇb‚Çô.
O objetivo √© obter o gradiente da fun√ß√£o de custo em rela√ß√£o aos pesos e vieses da camada, pois s√£o os √∫nicos par√¢metros que podemos alterar diretamente. Portanto, precisamos obter ‚àÇC‚Çô\‚àÇw‚Çô: a derivada parcial de C‚Çô em rela√ß√£o aos pesos; e ‚àÇC‚Çô\‚àÇb‚Çô derivada parcial de C‚Çô em rela√ß√£o aos vieses.¬†
Essas derivadas parciais s√£o obtidas atrav√©s da aplica√ß√£o da regra da cadeia, agrupando as vari√°veis de cada componente da sa√≠da:
Equa√ß√µes para os gradientes dos pesos e vieses da camada de¬†sa√≠daEmbora a defini√ß√£o dessas variadas j√° seja dada pela fonte principal, as equa√ß√µes n√£o s√£o complexas de diferenciar na m√£o.
Para ‚àÇz‚Çô\‚àÇw‚Çô: em uma derivada parcial, consideramos apenas a vari√°vel relacionada (w), tratando as demais como uma constante qualquer. Nessa equa√ß√£o aplicamos 2 regras b√°sicas de derivadas: a derivada de uma constante √© sempre 0 e a derivada de uma pot√™ncia √© dada pela regra  d/dx(x‚Åø) = n¬†. x‚Åø‚Åª¬π
No termo ‚àÇa‚Çô/‚àÇz‚Çô, o valor da derivada depende da fun√ß√£o de ativa√ß√£o (œÉ) utilizada. Para o termo gen√©rico, esse valor √© representado por œÉ'(z‚Çô): a aplica√ß√£o do valor de entrada √† derivada da fun√ß√£o œÉ.
O termo ‚àÇC‚Çô/‚àÇa‚Çô traz um detalhe que pega muito estudante de c√°lculo de cal√ßa curta: devemos considerar os termos entre par√™nteses (a - y) como uma fun√ß√£o interna f. Se temos 2 fun√ß√µes, a derivada final deve ser obtida pela aplica√ß√£o da regra da cadeia: ‚àÇC‚Çô/‚àÇa‚Çô = ‚àÇC‚Çô/‚àÇf¬†. ‚àÇf/‚àÇa‚Çô.
Diferencia√ß√£o da fun√ß√£o de custo do erro quadr√°tico m√©dio.Na derivada parcial ‚àÇz‚Çô\‚àÇb‚Çô tratamos w‚Çô e a‚Çô‚Çã‚ÇÅ como constantes, portanto o produto (w‚Çô¬†. a‚Çô‚Çã‚ÇÅ) tem derivada 0. A derivada do termo b‚Çô √© otida pela regra da pot√™ncia: d\db‚Çô(b‚Çô) = 1b‚Çô‚Å∞ = 1
Assim temos todos os componentes matem√°ticos para implementar a retropropaga√ß√£o. Finalmente podemos voltar a ver c√≥digo aqui. Para come√ßar, o c√°lculo depende do valor da soma ponderada z, que √© calculado durante a propaga√ß√£o dos valores na rede neural, implementada no artigo anterior. N√£o faz muito sentido recalcular esse valor, portanto modificamos o c√≥digo das camadas para armazenar o valor dessa soma durante a propaga√ß√£o:
pub struct Layer {
    neurons: Matrix,
    zed: Matrix,            //Termo z na retropropaga√ß√£o
    weights: Matrix,
    biases: Matrix,
    activation_function: fn(f64) -> f64,
    activation_derivative: fn(f64) -> f64, 
}

pub fn propagate(&mut self, input_neurons: &Matrix) 
        let dot_product = &(self.weights) * &input_neurons; 
        let biased_values = dot_product + &self.biases;
        assert!(biased_values.rows() == self.neurons.rows());
        //Biased_values deve ser uma matriz nx1
        for i in 0..biased_values.rows() {
            //Armazena o resultado para a fase de backprop
            self.zed[i][0] = biased_values[i][0]; 
            self.neurons[i][0] = (self.activation_function)(biased_values[i][0]);
        }
    }
Um detalhe importante √© que a derivada parcial deve ser tomada em rela√ß√£o a cada um dos pesos e vieses da camada de sa√≠da. Portanto, podemos visualizar essas derivadas em formato de matrizes:
Representa√ß√£o matricial das derivadas parciais obtidas durante a retropropaga√ß√£o. O operador ‚äô representa o produto elemento a elemento das¬†matrizesDepois disso podemos iniciar a implementa√ß√£o da camada de sa√≠da da rede neural. Para esse c√°lculo, nossa fun√ß√£o deve receber 3 par√¢metros:
1. O valor de sa√≠da esperado para nossa rede
2. O valor de ativa√ß√£o da camada anterior
3. A derivada da fun√ß√£o de custo
Ela retornar√° o gradiente dessa camada, representado por uma √∫nica matriz. Implementamos a fun√ß√£o com uma tradu√ß√£o direta das derivadas aplicadas a cada neur√¥nio da nossa rede neural.
pub struct Layer {
    neurons: Matrix,
    ...,
    weight_derivatives: Matrix, // Gradiente de erro dos pesos da camada
}

pub fn cost_derivative(activation_val: f64, expected_val: f64) -> f64 {
        2 * (activation_val - expected_val)
}

pub fn backpropagate_output_layer(
        &mut self,
        expected: &Matrix,
        prev_activations: &Matrix,
        cost_derivative: impl Fn(f64, f64) -> f64,
    ) {
        let mut deltas = Matrix::new(self.neurons.rows(), 1)
        for i in 0..self.neurons.rows() {
            //‚àÇC/‚àÇa = 2(a - y) - Derivada parcial de C por a
            let c_a_partial_derivative = 
              cost_derivative(self.neurons[i][0], expected[i][0]);
            //‚àÇaL/‚àÇz = activation'(z) - Derivada parcial de a por z
            let a_zed_partial_derivative = 
              self.activation.derivative(self.zed[i][0]);
            //Œ¥ = hadamard_product(‚àÇC/‚àÇa, ‚àÇaL/‚àÇz).
            //Detalhe: o vetor delta √© a derivada em fun√ß√£o dos vi√©ses 
            //‚àÇC/‚àÇb = ‚àÇz/‚àÇb * ‚àÇa/‚àÇz * ‚àÇC/‚àÇa j√° que ‚àÇz/‚àÇb = 1
            deltas[i][0] = c_a_partial_derivative * a_zed_partial_derivative;
            for j in 0..self.weights.cols() { 
                //Para cada peso, calcula a derivada parcial 
                //em rela√ß√£o ao valor do neur√¥nio
                self.weight_derivatives[i][j] = 
                  prev_activations[j][0] * deltas[i][0];
            }
        }
    }
Existem 2 detalhes dignos de nota nessa implementa√ß√£o:
1. O c√°lculo da derivada parcial em rela√ß√£o aos vieses est√° impl√≠cito na fun√ß√£o. Esse gradiente √© armazenado na matriz deltas¬†
2. O gradiente dos pesos pode ser representado como uma matriz, que armazena o valor de ajuste de cada camada. Essa intui√ß√£o n√£o estava clara na explica√ß√£o inicial, que trata o gradiente como um vetor √∫nico para todos os par√¢metros da rede.
Camadas Ocultas
Na camada de sa√≠da a taxa de varia√ß√£o da fun√ß√£o de custo √© calculada com base na ativa√ß√£o final (a‚Çô) da rede. Precisamos agora repetir o processo para as camadas ocultas, determinando a taxa de varia√ß√£o da fun√ß√£o de custo em rela√ß√£o a ativa√ß√£o de cada camada. Uma rede neural composta por N camadas, ordenadas de 0 a n, pode ser representadas pelo conjunto {0, 1,¬†‚Ä¶, n-2, n-1, n}.
A taxa de varia√ß√£o da fun√ß√£o de custo em rela√ß√£o √† camada final (‚àÇC/‚àÇa‚Çô) j√° foi calculada previamente. Como a retropropaga√ß√£o funciona em passos "para tr√°s", o pr√≥ximo gradiente a ser calculado refere-se √† camada anterior: ‚àÇC/‚àÇa‚Çô‚Çã‚ÇÅ. Retomando a defini√ß√£o da ativa√ß√£o a‚Çô = œÉ(w‚Çô¬†. a‚Çô‚Çã‚ÇÅ + b‚Çô), sabemos que o efeito da ativa√ß√£o da camada n-1 se manifesta apenas na soma ponderada, nosso z‚Çô. Portanto, a taxa de varia√ß√£o da fun√ß√£o de custo em rela√ß√£o a ativa√ß√£o a‚Çô‚Çã‚ÇÅ √© dado em termos da taxa de varia√ß√£o de z‚Çô em rela√ß√£o √† ativa√ß√£o a‚Çô‚Çã‚ÇÅ: ‚àÇz‚Çô/‚àÇa‚Çô‚Çã‚ÇÅ.
Como o valor final da rede continua sendo afetado pelos par√¢metros da camada de sa√≠da, os demais termos da regra da cadeia permanecem na equa√ß√£o:
O primeiro detalhe dessa equa√ß√£o: o produto em destaque j√° foi calculado quando implementamos a retropropaga√ß√£o para a camada de sa√≠da. Uma repeti√ß√£o similar ser√° encontrada se expandirmos a equa√ß√£o para a camada n-2: o produto ‚àÇa‚Çô‚Çã‚ÇÅ/‚àÇz‚Çô‚Çã‚ÇÅ¬†. ‚àÇz‚Çô‚Çã‚ÇÅ /‚àÇa‚Çô‚Çã‚ÇÅ ser√° repetido. Essas repeti√ß√µes ocorrem sucessivamente a cada passo de propaga√ß√£o. Por conta disso, √© comum ver o produto representado pelo s√≠mbolo ùúπ nos materiais de refer√™ncia.
Para n√£o recalcular esses valores toda vez, adicionamos uma matriz delta como membro da struct que representa nossas camadas. Tamb√©m ajustamos a fun√ß√£o de retropropaga√ß√£o da camada de sa√≠da para armazenar esses valores:
pub struct Layer {
    neurons: Matrix,
    zed: Matrix,            //Vari√°vel z na retropropaga√ß√£o
    deltas: Matrix,         //Vetor de erro / gradiente de vieses.
    weight_derivatives: Matrix, // Gradiente de erro dos pesos da camada 
    weights: Matrix,
    biases: Matrix,
    activation_function: fn(f64) -> f64,
    activation_derivative: fn(f64) -> f64, 
}
pub fn backpropagate_output_layer(...) {
    //let mut deltas = ... Removemos a vari√°vel tempor√°ria
    for i in 0..self.neurons.rows() {
        ///...
        self.deltas[i][0] = 
          c_a_partial_derivative * a_zed_partial_derivative;
        for j in 0..self.weights.cols() { 
            self.weight_derivatives[i][j] = 
              prev_activations[j][0] * self.deltas[i][0];
        }
    }
}
√â essa repeti√ß√£o de termos que justifica a l√≥gica da retropropaga√ß√£o: os termos s√£o calculados uma √∫nica vez e propagados para tr√°s.
Para obter o valor da derivada ‚àÇz‚Çô/‚àÇa‚Çô‚Çã‚ÇÅ consideramos a defini√ß√£o de z‚Çô. A l√≥gica para a diferencia√ß√£o √© exatamente a mesma usada anteriormente, com a √∫nica altera√ß√£o sendo o termo que estamos diferenciando:
Novamente, n√£o podemos alterar diretamente o valor da ativa√ß√£o da camada,  portanto precisamos "quebrar" a derivada ‚àÇz‚Çô/‚àÇa‚Çô‚Çã‚ÇÅ para trat√°-la em rela√ß√£o aos par√¢metros ajust√°veis: pesos e vieses. Usamos os mesmos passos descritos para a camada de sa√≠da e obtemos as derivadas parciais em rela√ß√£o aos pesos e vieses da pen√∫ltima camada:
Para esta equa√ß√£o, as derivadas parciais ‚àÇa‚Çô‚Çã‚ÇÅ/‚àÇz‚Çô‚Çã‚ÇÅ, ‚àÇz‚Çô‚Çã‚ÇÅ/‚àÇw‚Çô‚Çã‚ÇÅ e ‚àÇz‚Çô‚Çã‚ÇÅ/‚àÇb‚Çô‚Çã‚ÇÅ s√£o exatamente as mesmas obtidas para a camada de sa√≠da n, portanto podemos replicar as f√≥rmulas obtidas naquela se√ß√£o.
A grande diferen√ßa para esse c√°lculo em rela√ß√£o ao gradiente da camada de sa√≠da est√° na conex√£o dos neur√¥nios dessa camada. Para a camada final, o valor de ativa√ß√£o dos neur√¥nios forma um vetor que tem uma rela√ß√£o direta com o vetor do resultado esperado. Se imaginamos o resultado esperado como um conjunto de neur√¥nios, podemos dizer que cada neur√¥nio da camada de sa√≠da est√° diretamente conectado com apenas 1 neur√¥nio do resultado: seu par na mesma posi√ß√£o. Portanto, a altera√ß√£o do valor de um neur√¥nio da camada de sa√≠da impacta apenas 1 "neur√¥nio" do resultado esperado.
As "conex√µes" da camada de sa√≠da relacionam cada neur√¥nio ao sinal equivalente no resultado esperado.Para as camadas ocultas, isso n√£o √© verdade. Na nossa rede neural densa, cada neur√¥nio da camada n-1 est√° conectado com todos os neur√¥nios da camada n. Isso quer dizer que altera√ß√µes no valor de um neur√¥nio na camada n-1 impactam o valor de todos os neur√¥nios da camada n. Para determinar como o valor da ativa√ß√£o a‚Çô‚Çã‚ÇÅ impacta o valor da fun√ß√£o de custo, precisamos tra√ßar como esse valor altera o sinal de cada neur√¥nio da camada seguinte.
Para camadas ocultas, o sinal de um neur√¥nio est√° conectado com todos os sinais da pr√≥xima camada. Para determinar o erro deste sinal, √© necess√°rio seguir todas as conex√µes com a pr√≥xima¬†camada.No c√°lculo do gradiente, para cada neur√¥nio k, esse efeito √© expressado pelo somat√≥rio de todas as conex√µes do neur√¥nio com a camada seguinte:
Retomando o c√≥digo,  a fun√ß√£o de retropropaga√ß√£o para as camadas ocultas depende de 2 fatores:
Da camada seguinte, de onde deve obter os valores do produto ùúπ e dos pesos da camada. A camada √© fornecida atrav√©s de uma refer√™ncia emprestada &next_layer¬†
Os valores de ativa√ß√£o da camada anterior, transmitidos diretamente em formato de matriz

pub fn backpropagate_hidden_layer(
        &mut self,
        next_layer: &Layer<T>,
        prev_activations: &Matrix,
    ) {
    //let weight_transpose = next_layer.weights.transpose();
    for i in 0..self.neurons.rows() {
        //‚àÇaL/‚àÇz = activation'(z) - Derivada parcial de a por z
        let a_zed_partial_derivative = 
          self.activation.derivative(self.zed[i][0]);
        let mut c_a_partial_derivative = 0.0;
        //Somat√≥rio ‚àÇz/‚àÇa_(l-1) * Œ¥_l
        for j in 0..next_layer.weights.rows() {
            c_a_partial_derivative += 
              next_layer.weights[j][i] * next_layer.deltas[j][0];
        }
        //Œ¥ = ‚àÇa_(l-1)/‚àÇz_(l-1) * sum(‚àÇz_l/‚àÇa_(l-1) * Œ¥l)
        self.deltas[i][0] = c_a_partial_derivative * a_zed_partial_derivative;
        for j in 0..self.weights.cols() {
            //‚àÇz/‚àÇw = a_(L-1).
            //‚àÇC/‚àÇCw_(l-1) = ‚àÇz_(l-1)/‚àÇw_L-1 * ‚àÇa_(l-1)/‚àÇz_(l-1) * sum(‚àÇz_l/‚àÇa_(l-1) * Œ¥l)
            //‚àÇC/‚àÇCw_(l-1) = a_(L-1) * Œ¥
            self.weight_derivatives[i][j] = prev_activations[j][0] * self.deltas[i][0];
        }
    }
}
Detalhe importante: na implementa√ß√£o direta da multiplica√ß√£o de matrizes, a matriz de pesos deveria ser transposta para que o n√∫mero de colunas seja equivalente ao n√∫mero de linhas do vetor delta. A grande quest√£o √© que a opera√ß√£o de transposi√ß√£o √© desnecess√°ria nessa implementa√ß√£o. Podemos simplesmente acessar a matriz invertendo os √≠ndices, de forma que i represente a coluna e j represente a linha. Essa equival√™ncia √© sutilmente apontada pelo material do 3b1b na invers√£o dos √≠ndices na representa√ß√£o da matriz de pesos.
Those indices, jk, might feel backwards at first, but it lines up with how you'd index the weight matrix
Um ponto chave do algoritmo de retropropaga√ß√£o √© a equival√™ncia do vetor deltas com o gradiente de custo em rela√ß√£o aos vieses da camada. √â f√°cil de ignorar essa correspond√™ncia na explica√ß√£o apresentada no material base pois a vari√°vel ùúπ nunca √© definida no processo. Novamente, a simplifica√ß√£o auxilia na compreens√£o intuitiva mas n√£o √© a melhor fonte para uma implementa√ß√£o desse algoritmo.
A escrita dos testes da retropropaga√ß√£o segue a mesma l√≥gica dos testes de propaga√ß√£o: fixamos os valores das camadas de nossa rede neural e utilizamos uma calculadora de matrizes para gerar o resultado esperado. O c√≥digo foi anexado no final do artigo.
Treinando a Rede Neural (e a paci√™ncia)
Agora que todos os c√°lculos foram traduzidos para uma implementa√ß√£o de c√≥digo s√≥ nos resta "montar os bloquinhos" para juntar tudo na implementa√ß√£o do treinamento, certo? Come√ßamos com uma struct para representar a rede neural:
struct NeuralNetwork {
    layers: Vec<Layer<Relu>>, //Camadas com fun√ß√£o de ativa√ß√£o ReLu
    learning_rate: f64        //Hiperparametro
}
Criamos a fun√ß√£o de treinamento passo a passo. A fun√ß√£o dever√° receber como par√¢metro uma matriz representando a entrada e uma segunda matriz com o resultado esperado.
Primeiro, a fun√ß√£o deve classificar os dados de entrada e gerar sua sa√≠da. Iniciamos propagando a representa√ß√£o matricial da entrada na primeira camada de nossa rede neural para gerar a primeira representa√ß√£o. Depois precisamos apenas propagar essa representa√ß√£o camada por camada, percorrendo a lista completa sequencialmente:
pub fn classify(&mut self, input: Matrix) {
    assert!(!self.layers.is_empty());
    //Propaga a primeira camada com a entrada
    //(considera que a primeira camada √© uma camada oculta)
    self.layers[0].propagate(&input);
    //Propaga as camadas remanescentes com a ativa√ß√£o anterior
    for i in 1..self.layers.len() {
        self.layers[i].propagate(self.layers[i-1].neurons());
    }
}
Infelizmente n√£o √© t√£o simples.
No √∫ltimo artigo apresentei parte das regras de propriedade da linguagem que formam um controle robusto de mem√≥ria. Outra se√ß√£o dessas regras mostra as caras nesse erro, tratando agora do compartilhamento de mem√≥ria:
Um objeto pode conter n refer√™ncias imut√°veis emprestadas
Apenas 1 refer√™ncia mut√°vel pode ser emprestada em um dado escopo.
Se houve um empr√©stimo mut√°vel, n√£o √© poss√≠vel emprestar uma refer√™ncia imut√°vel no mesmo escopo. O mesmo √© v√°lido na dire√ß√£o oposta.

Essencialmente, as regras acima garantem que m√∫ltiplos usu√°rios podem ler o conte√∫do de uma se√ß√£o de mem√≥ria simultaneamente, desde que nenhum delas queira escrever nessa se√ß√£o. Assim que algu√©m declara inten√ß√£o de escrita via empr√©stimo mut√°vel, a linguagem impede que outros usu√°rios leiam aquele endere√ßo de mem√≥ria, ou declarem inten√ß√£o de escrita, at√© que as opera√ß√µes de escrita (o escopo do empr√©stimo) sejam finalizadas. Isso garante que n√£o haver√£o tentativas simult√¢neas de escrita, gerando condi√ß√µes de corrida, e que os leitores n√£o acessar√£o mem√≥ria inv√°lida.
O erro se d√° pela defini√ß√£o da fun√ß√£o propagate:
pub fn propagate(&mut self, input_neurons: &Matrix)
Seguindo a defini√ß√£o, o par√¢metro self (o objeto no qual o m√©todo √© chamado) deve ser uma refer√™ncia mut√°vel. Isso √© auto evidente, j√° que a propaga√ß√£o dever√° alterar a camada. O ponto de conflito aqui √© que o acesso aos elementos de um array de camadas da rede neural √© feito atrav√©s de empr√©stimo impl√≠cito do array, utilizando o tipo exigido pelo elemento no contexto. Isso significa que temos uma refer√™ncia mut√°vel ao array self.layers para obter a camada atual.¬†
Em contraste com essa refer√™ncia, a matriz de neur√¥nios da camada anterior √© recebida como uma refer√™ncia imut√°vel. Como a camada anterior est√° armazenada no mesmo vetor, temos uma refer√™ncia imut√°vel ao array no acesso self.layers[i-1].neurons(), portanto violamos a regra 3 e o compilador nos impede de fazer m*.
Para que a opera√ß√£o tenha sucesso precisamos de 2 refer√™ncias distintas aos elementos. Essas refer√™ncias podem ser obtidas partindo o array em 2 fatias: a primeira cont√©m as camadas que j√° foram propagadas, enquanto a segunda apresenta as camadas que ainda devem processar os dados. Como uma das refer√™ncias deve ser mut√°vel, precisamos seguir a sugest√£o do compilador e utilizar o m√©todo `split_at_mut`. Utilizando o √≠ndice da camada atual como par√¢metro dessa fun√ß√£o temos exatamente as janelas desejadas, resultando na implementa√ß√£o abaixo:
pub fn classify(&mut self, input: &Matrix) {
    assert!(!self.layers.is_empty());
    //Propaga a primeira camada com a entrada
    //(considera que a primeira camada √© uma camada oculta)
    self.layers[0].propagate(&input);
    //Propaga as camadas remanescentes
    for i in 1..self.layers.len() {
        //Separa em 2 slices: [0..i) e [i..len)
        let (prev_layers, layers_to_propagate) = self.layers.split_at_mut(i);
        layers_to_propagate[0].propagate(prev_layers[i - 1].neurons());
    }
}
Agora temos 1 refer√™ncia mut√°vel ao slice layers_to_propagate, cujo primeiro elemento √© a camada que ser√° propagada no momento, e uma refer√™ncia imut√°vel a prev_layers, que inclui todas as camadas j√° processadas.¬†
Com a classifica√ß√£o da entrada feita pela propaga√ß√£o, agora √© necess√°rio calcular e retropropagar o erro para permitir a rede aprenda algo com essa opera√ß√£o. J√° implementamos m√©todos distintos para a retropropaga√ß√£o na camada de sa√≠da e nas camadas ocultas. Come√ßamos ent√£o pela camada de sa√≠da da rede neural:
//Derivada da fun√ß√£o de custo
pub fn cost_derivative_mse(x: f64, y: f64) -> f64 {
        2.0 * (x - y)
}

pub fn generate_gradients(&mut self, input: Matrix, expected_output: Matrix) {
    //Limita o escopo dos slices para evitar erro de borrow na retropropaga√ß√£o
    {
        let (hidden_layers, output_layers) = 
          self.layers.split_at_mut(last_layer_index);
        
        output_layers[0].backpropagate_output_layer(
            &expected_output,
            hidden_layers[last_layer_index - 1].neurons(),
            NeuralNetwork::cost_derivative_mse,
        );
    }
    ...
}
Usamos a mesma t√©cnica de fatiar o array de camadas para evitar os erros devido ao empr√©stimo mut√°vel da camada de sa√≠da. Para evitar que esse problema seja constante nos pr√≥ximos passos, utilizei um bloco de c√≥digo para criar um escopo limitado e reduzir o tempo de vida dos slices criados para essa etapa. Isso garante que n√£o existir√£o refer√™ncias ao array de camadas ap√≥s essa se√ß√£o de c√≥digo. Pensando logicamente, extrair essa se√ß√£o de c√≥digo.
Com a camada de sa√≠da resolvida, percorremos as camadas ocultas de tr√°s para a frente, executando a retropropaga√ß√£o at√© a 3¬™ camada:
pub fn generate_gradients(&mut self, input: Matrix, expected_output: Matrix) {
    //Limita o escopo dos slices para evitar erro de borrow na retropropaga√ß√£o
    {
        let (hidden_layers, output_layers) = 
          self.layers.split_at_mut(last_layer_index);
        
        output_layers[0].backpropagate_output_layer(
            &expected_output,
            hidden_layers[last_layer_index - 1].neurons(),
            NeuralNetwork::cost_derivative_mse,
        );
    }
    for i in (2..last_layer_index).rev() { 
        //Inverte o range para percorrer de N at√© 2
        //slices [0..i) e [i..len()] (Novamente lidando com borrow checker)
        let (propagation_layers, done_layers) = self.layers.split_at_mut(i);
        let (coming_layers, current_layers) = 
            propagation_layers.split_at_mut(i - 1);

        current_layers[0]
            .backpropagate_hidden_layer(
              &done_layers[0], 
              coming_layers[i - 2].neurons());
    }
    let (remaining_layers, done_layers) = self.layers.split_at_mut(2);
    ...//tratar segunda camada da rede
}
Nesse ponto a t√°tica de criar m√∫ltiplos slices para o array de camadas come√ßa a demonstrar sua fragilidade. Para a retropropaga√ß√£o das camadas ocultas, √© necess√°rio obter 3 refer√™ncias distintas:
1. A camada atual: i-1
2. A camada posterior: i, de onde precisamos obter os pesos e o vetor delta
3. A camada anterior: i-2, contendo os valores de ativa√ß√£o
Isso torna o c√≥digo de divis√£o do array dentro do la√ßo de repeti√ß√£o bem confuso, sendo necess√°rio manipular 4 slices distintos e equilibrar os √≠ndices de cada um deles em rela√ß√£o ao √≠ndice da camada inicial. Tamb√©m precisamos tratar o caso da 2¬™ camada separadamente, do contr√°rio o √≠ndice [i-2] resultar√° em uma posi√ß√£o obviamente inv√°lida (1‚Äì2 = -1).
Foi aqui que eu decidi dar um passo atr√°s e repensar a defini√ß√£o dessas fun√ß√µes antes de brigar novamente com o compilador.
Refatora√ß√£o do C√≥digo das¬†Camadas
Um primeiro ponto que pode melhorar a clareza do c√≥digo √© desvincular os gradientes gerados pela retropropaga√ß√£o da pr√≥pria camada. Isso √© muito relevante pois, em uma aplica√ß√£o real, o valor final de ajuste dos par√¢metros da camada n√£o √© dado pelos gradientes de um √∫nico caso de treinamento, mas sim da m√©dia dos gradientes gerados para cada caso apresentado √† nossa rede.
Para que isso seja poss√≠vel, a fun√ß√£o de retropropa√ß√£o deve retornar os gradientes calculados para os pesos e para os vieses da camada. Agrupamos os dois em uma struct de dados e ajustamos nossa camada e as fun√ß√µes de retropropaga√ß√£o apropriadamente:
pub struct Gradient {
    pub weight: Matrix,
    pub delta: Matrix,
}
//Removemos delta e weight_derivatives da struct
pub struct Layer {
    neurons: Matrix,
    zed: Matrix,
    weights: Matrix,
    biases: Matrix,
    activation_function: fn(f64) -> f64,
    activation_derivative: fn(f64) -> f64, 
}

pub fn backpropagate_output_layer(
    &mut self,
    expected: &Matrix,
    prev_activations: &Matrix,
    cost_derivative: &dyn Fn(f64, f64) -> f64,
) -> Gradient {
    let mut weight_derivatives = 
      Matrix::new(self.weights.rows(), self.weights.cols());
    let mut deltas = Matrix::new(self.neuron_qty(), 1);
    ... //C√°lculo permanece o mesmo
    //Retorna um objeto Gradient transportando as matrizes
    Gradient {
        weight: weight_derivatives,
        delta: deltas,
    }
}

pub fn backpropagate_hidden_layer(
    &mut self,
    next_layer_weights: &Matrix, //Separa pesos do gradiente
    next_layer_deltas: &Matrix, 
    prev_activations: &Matrix,
) -> Gradient {
    let mut weight_derivatives = 
      Matrix::new(self.weights.rows(), self.weights.cols());
    let mut deltas = Matrix::new(self.neuron_qty(), 1);
    ... //C√°lculo permanece o mesmo
    Gradient {
        weight: weight_derivatives,
        delta: deltas,
    }
}
Nossa fun√ß√£o de treinamento √© ajustada para armazenar esses gradientes em uma cole√ß√£o tempor√°ria. Tamb√©m consegui simplificar a gest√£o dos √≠ndices das camadas no processamento das camadas ocultas, cortando o array em torno da camada atual de processamento:
1. Um slice contendo as camadas que ser√£o processadas posteriormente √© gerado quando dividimos no √≠ndice da camada atual **i**. A camada i-1 √© sempre o √∫ltimo elemento desse vetor, portanto [i-1] √© um acesso v√°lido enquanto nosso range n√£o passa de 1;
2. A camada atual √© isolada das demais pela cria√ß√£o de um *slice* com um √∫nico elemento. Nessa opera√ß√£o, a camada i+1 √© o primeiro elemento do segundo *slice*. O acesso ao √≠ndice [0] √© sempre v√°lido se o range inicia na pen√∫ltima camada do array;
3. Por fim, simplificamos o acesso ao gradiente de erros da camada posterior com a ordem de adi√ß√£o dos elementos nesse vetor. Se adicionamos sempre no in√≠cio da cole√ß√£o, o √∫ltimo gradiente calculado ser√° sempre obtido pelo primeiro elemento do vetor. Essa l√≥gica de inser√ß√£o √© o motivo de utilizarmos VecDeque em lugar de Vec para armazenar os gradientes.
pub fn generate_gradients(&mut self, input: Matrix, expected_output: Matrix) 
    -> VecDeque<Gradient> { //Retorna os gradientes
    
    let mut gradients: VecDeque<Gradient> = 
      VecDeque::with_capacity(self.layers.len());
    {
        let (hidden_layers, output_layers) = 
            self.layers.split_at_mut(last_layer_index);
        let gradient = output_layers[0].backpropagate_output_layer(
            &expected_output,
            hidden_layers[last_layer_index - 1].neurons(),
            &NeuralNetwork::cost_derivative_mse,
        );
        //Adiciona no in√≠cio da "fila"
        gradients.push_front(gradient);
    }
    //Usando rev() para percorrer as camadas de tr√°s para frente
    for i in (0..last_layer_index).rev() {
        
        //slices [0..i) e [i..len()-1) 
        let (initial_layers, current_and_done_layers) = 
            self.layers.split_at_mut(i);
        let (current_layer, done_layers) = 
            current_and_done_layers.split_at_mut(1);
        //Para a primeira camada oculta, a ativa√ß√£o pr√©via √© a entrada
        let prev_activations = if i == 0 {
            &input
        } else {
            initial_layers[i - 1].neurons()
        };

        let gradient = current_layer[0].backpropagate_hidden_layer(
            &done_layers[0].weights(),
            &gradients[0].delta,
            prev_activations,
        );
        gradients.push_front(gradient);
    }
    gradients
}
Ap√≥s a gera√ß√£o dos gradientes a rede neural deve ser ajustada.¬†
pub fn adjust_parameters(&mut self, VecDeque<Gradient>)
  {
    assert!(gradients.len() == self.layers.len());
    //zip: agrupa 2 iteradores. 
    //O la√ßo √© finalizado quando um deles chega ao fim.
    //No nosso caso, ambos ter√£o o mesmo tamanho, dado o assert! acima.
    for (layer, gradient) in self.layers.iter_mut().zip(gradients) {
        layer.adjust_parameters(gradient, self.learning_rate);
    }
}
//impl struct Layer 
pub fn adjust_parameters(&mut self, gradients: Gradient, learning_rate: f64) {
    //Ajusta os pesos
    self.weights -= &gradients.weight.scalar_product(learning_rate);
    //Ajusta os vi√©ses
    self.biases -= &gradients.delta.scalar_product(learning_rate);
}
Finalmente temos a fun√ß√£o de treinamento implementada:
pub fn train(&mut self, input: Matrix, expected_output: Matrix) 
    self.classify(&input);
    let gradients = self.generate_gradients(input, expected_output);
    self.adjust_parameters(gradients);
}